{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrate Local Or Remote Functions And Full Pipelines\n",
    "  --------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project to host our functions, jobs and artifacts\n",
    "\n",
    "Projects are used to package multiple functions, workflows, and artifacts. We usually store project code and definitions in a Git archive.\n",
    "\n",
    "The following code creates a new project in a local dir and initialize git tracking on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-11-20 13:35:39,813 [warning] warning!, server (0.5.4-rc1) and client (0.5.4) ver dont match\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlrun\n",
    "\n",
    "# set project name and dir\n",
    "project_name = 'sk-project-dask'\n",
    "project_dir = './project'\n",
    "\n",
    "# specify artifacts target location\n",
    "artifact_path = mlrun.set_environment(api_path = mlrun.mlconf.dbpath or 'http://mlrun-api:8080',\n",
    "                                      artifact_path = os.path.abspath('./'),\n",
    "                                      project = project_name,)\n",
    "\n",
    "# set project\n",
    "sk_dask_proj = mlrun.new_project(project_name, project_dir, init_git=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and run a functions\n",
    "\n",
    "load the function object from .py .yaml file or function hub (marketplace)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load function from local file\n",
    "dsf = sk_dask_proj.set_function('/User/demos/scikit-learn-pipeline-dask/project/sklearn-classifier-dask.py', \n",
    "                                name='dask_classifier', \n",
    "                                kind=\"job\",\n",
    "                                image=\"mlrun/ml-models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up function specs for dask\n",
    "dsf.spec.remote = True\n",
    "dsf.spec.replicas = 6\n",
    "dsf.spec.service_type = 'NodePort'\n",
    "dsf.with_limits(mem=\"4G\", cpu=6)\n",
    "dsf.spec.nthreads = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up function from local file\n",
    "dsjob = sk_dask_proj.set_function(\"/User/demos/scikit-learn-pipeline-dask/project/daskjob.py\", \n",
    "                                  name='dsjob', \n",
    "                                  kind=\"job\", \n",
    "                                  image=\"mlrun/ml-models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "describejob = sk_dask_proj.set_function(\"/User/demos/scikit-learn-pipeline-dask/project/describe.py\", \n",
    "                                          name='describe', \n",
    "                                          kind=\"job\", \n",
    "                                          image=\"mlrun/ml-models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Fully Automated ML Pipeline\n",
    "\n",
    "#### Add more functions to our project to be used in our pipeline (from the functions hub/marketplace)\n",
    "\n",
    "Describe data, train and eval model with dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define and save a pipeline \n",
    "\n",
    "The following workflow definition will be written into a file, it describes a Kubeflow execution graph (DAG)<br>\n",
    "and how functions and data are connected  to form an end to end pipeline. \n",
    "\n",
    "* Ingest data\n",
    "* Describe data\n",
    "* Train, test and evaluate with dask\n",
    "\n",
    "Check the code below to see how functions objects are initialized and used (by name) inside the workflow.<br>\n",
    "The `workflow.py` file has two parts, initialize the function objects and define pipeline dsl (connect the function inputs and outputs).\n",
    "\n",
    "> Note: the pipeline can include CI steps like building container images and deploying models as illustrated  in the following example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting project/workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile project/workflow.py\n",
    "from kfp import dsl\n",
    "from mlrun import mount_v3io\n",
    "\n",
    "funcs    = {}\n",
    "LABELS   = \"label\"\n",
    "DATA_URL = \"/User/iris.csv\"\n",
    "#DATA_URL = \"/User/yellow_tripdata_2019-01_subset.csv\"\n",
    "\n",
    "\n",
    "# init functions is used to configure function resources and local settings\n",
    "def init_functions(functions: dict, project=None, secrets=None):\n",
    "    for f in functions.values():\n",
    "        f.apply(mount_v3io())\n",
    "        pass\n",
    "     \n",
    "    \n",
    "@dsl.pipeline(\n",
    "    name=\"Demo training pipeline\",\n",
    "    description=\"Shows how to use mlrun.\"\n",
    ")\n",
    "def kfpipeline():\n",
    "    \n",
    "    # init_dask\n",
    "    dask_init = funcs['dsjob'].as_step(\n",
    "        handler=\"hndlr\",\n",
    "        params={\"client_url\" : \"db://default/mydask\"},\n",
    "        outputs=['client'])\n",
    "    \n",
    "    # describe data\n",
    "    describe = funcs['describe'].as_step(\n",
    "        handler=\"describe\",\n",
    "        inputs={\"dataset\"   : DATA_URL,\n",
    "                \"dask_address\"  : dask_init.outputs['client']})\n",
    "    \n",
    "    # get data, train, test and evaluate \n",
    "    train = funcs['dask_classifier'].as_step(\n",
    "        name=\"train-skrf\",\n",
    "        handler=\"train_model\",\n",
    "        params={\"label_column\"    : LABELS,\n",
    "                \"test_size\"       : 0.10,\n",
    "                \"model_pkg_class\" : \"sklearn.ensemble.RandomForestClassifier\"},\n",
    "        inputs={\"dataset\"   : DATA_URL,\n",
    "                \"dask_address\"  : dask_init.outputs['client']},\n",
    "        outputs=['model', 'test_set'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the workflow file as \"main\", embed the workflow code into the project YAML\n",
    "sk_dask_proj.set_workflow('main', 'workflow.py', embed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the project definitions to a file (project.yaml), it is recommended to commit all changes to a Git repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_dask_proj.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run-pipeline'></a>\n",
    "## Run a pipeline workflow\n",
    "use the `run` method to execute a workflow, you can provide alternative arguments and specify the default target for workflow artifacts.<br>\n",
    "The workflow ID is returned and can be used to track the progress or you can use the hyperlinks\n",
    "\n",
    "> Note: The same command can be issued through CLI commands:<br>\n",
    "    `mlrun project my-proj/ -r main -p \"v3io:///users/admin/mlrun/kfp/{{workflow.uid}}/\"`\n",
    "\n",
    "The `dirty` flag allow us to run a project with uncommited changes (when the notebook is in the same git dir it will always be dirty)<br>\n",
    "The `watch` flag will wait for the pipeline to complete and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-11-20 13:35:40,202 [info] using in-cluster config.\n",
      "> 2020-11-20 13:35:40,333 [warning] warning!, server (0.5.4-rc1) and client (0.5.4) ver dont match\n",
      "> 2020-11-20 13:35:40,667 [warning] warning!, server (0.5.4-rc1) and client (0.5.4) ver dont match\n",
      "> 2020-11-20 13:35:40,760 [warning] warning!, server (0.5.4-rc1) and client (0.5.4) ver dont match\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.dsteam.iguazio-cd1.com/pipelines/#/experiments/details/f7fd182e-113f-4ad5-8123-63ecd237b9eb\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.dsteam.iguazio-cd1.com/pipelines/#/runs/details/9503dab6-545b-4c75-bb7b-1336d98d5cbc\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-11-20 13:35:40,963 [info] Pipeline run id=9503dab6-545b-4c75-bb7b-1336d98d5cbc, check UI or DB for progress\n",
      "> 2020-11-20 13:35:40,963 [info] waiting for pipeline run completion\n",
      "> 2020-11-20 13:36:31,064 [warning] warning!, server (0.5.4-rc1) and client (0.5.4) ver dont match\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Run Results</h2>Workflow 9503dab6-545b-4c75-bb7b-1336d98d5cbc finished, status=Succeeded<br>click the hyper links below to see detailed results<br><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>uid</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div title=\"76367c0310e64b4787e572261977000c\"><a href=\"https://mlrun-ui.default-tenant.app.dsteam.iguazio-cd1.com/projects/sk-project-dask/jobs/76367c0310e64b4787e572261977000c/info\" target=\"_blank\" >...1977000c</a></div></td>\n",
       "      <td>Nov 20 13:36:01</td>\n",
       "      <td>completed</td>\n",
       "      <td>describe-describe</td>\n",
       "      <td></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result\" title=\"/files/demos/scikit-learn-pipeline-dask/pipe/9503dab6-545b-4c75-bb7b-1336d98d5cbc/describe.csv\">describe</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><div title=\"61d1ecaf62f749f99074096db1bd3d9a\"><a href=\"https://mlrun-ui.default-tenant.app.dsteam.iguazio-cd1.com/projects/sk-project-dask/jobs/61d1ecaf62f749f99074096db1bd3d9a/info\" target=\"_blank\" >...b1bd3d9a</a></div></td>\n",
       "      <td>Nov 20 13:36:02</td>\n",
       "      <td>completed</td>\n",
       "      <td>train-skrf</td>\n",
       "      <td><div class=\"dictlist\">micro=0.9935941828254847</div><div class=\"dictlist\">macro=0.9910470085470084</div><div class=\"dictlist\">precision-2=1.0</div><div class=\"dictlist\">precision-0=0.8461538461538461</div><div class=\"dictlist\">precision-1=0.9166666666666666</div><div class=\"dictlist\">recall-2=1.0</div><div class=\"dictlist\">recall-0=0.9166666666666666</div><div class=\"dictlist\">recall-1=0.8461538461538461</div><div class=\"dictlist\">f1-2=1.0</div><div class=\"dictlist\">f1-0=0.8799999999999999</div><div class=\"dictlist\">f1-1=0.8799999999999999</div></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result\" title=\"/files/demos/scikit-learn-pipeline-dask/pipe/9503dab6-545b-4c75-bb7b-1336d98d5cbc/ROCAUC.html\">ROCAUC</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result\" title=\"/files/demos/scikit-learn-pipeline-dask/pipe/9503dab6-545b-4c75-bb7b-1336d98d5cbc/ClassificationReport.html\">ClassificationReport</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result\" title=\"/files/demos/scikit-learn-pipeline-dask/pipe/9503dab6-545b-4c75-bb7b-1336d98d5cbc/ConfusionMatrix.html\">ConfusionMatrix</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result\" title=\"/files/demos/scikit-learn-pipeline-dask/pipe/9503dab6-545b-4c75-bb7b-1336d98d5cbc/FeatureImportances.html\">FeatureImportances</div><div title=\"/User/demos/scikit-learn-pipeline-dask/pipe/9503dab6-545b-4c75-bb7b-1336d98d5cbc/models\">model</div><div title=\"/User/demos/scikit-learn-pipeline-dask/pipe/9503dab6-545b-4c75-bb7b-1336d98d5cbc/models/standard_scaler\">standard_scaler</div><div title=\"/User/demos/scikit-learn-pipeline-dask/pipe/9503dab6-545b-4c75-bb7b-1336d98d5cbc/models/label_encoder\">label_encoder</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result\" title=\"/files/demos/scikit-learn-pipeline-dask/pipe/9503dab6-545b-4c75-bb7b-1336d98d5cbc/data/test_set.csv\">test_set</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><div title=\"dc4b6477efdc403aa7dac3b601474b85\"><a href=\"https://mlrun-ui.default-tenant.app.dsteam.iguazio-cd1.com/projects/sk-project-dask/jobs/dc4b6477efdc403aa7dac3b601474b85/info\" target=\"_blank\" >...01474b85</a></div></td>\n",
       "      <td>Nov 20 13:35:47</td>\n",
       "      <td>completed</td>\n",
       "      <td>dsjob-hndlr</td>\n",
       "      <td></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result\" title=\"/files/demos/scikit-learn-pipeline-dask/pipe/9503dab6-545b-4c75-bb7b-1336d98d5cbc/client.csv\">client</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "artifact_path = os.path.abspath('./pipe/{{workflow.uid}}')\n",
    "run_id = sk_dask_proj.run(\n",
    "    'main',\n",
    "    arguments={}, \n",
    "    artifact_path=artifact_path, \n",
    "    dirty=False, watch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-11-20 13:39:32,395 [warning] warning!, server (0.5.4-rc1) and client (0.5.4) ver dont match\n"
     ]
    }
   ],
   "source": [
    "!mlrun clean -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[back to top](#top)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
